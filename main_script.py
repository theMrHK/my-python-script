import requests
from telegram import Bot
from datetime import datetime
from pytz import timezone
import asyncio
from urllib.parse import quote
import logging
import re
import html

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

TOKEN = " "
CHANNEL_ID = "@Mazeruni_Xaver"

class WikipediaFetcher:
    def __init__(self):
        self.base_url = "https://mzn.wikipedia.org/w/api.php"
        self.month_names = [
            "Ú˜Ø§Ù†ÙˆÛŒÙ‡", "ÙÙˆØ±ÛŒÙ‡", "Ù…Ø§Ø±Ø³", "Ø¢ÙˆØ±ÛŒÙ„", "Ù…Ù‡", "Ú˜ÙˆØ¦Ù†",
            "Ú˜ÙˆØ¦ÛŒÙ‡", "Ø§ÙˆØª", "Ø³Ù¾ØªØ§Ù…Ø¨Ø±", "Ø§Ú©ØªØ¨Ø±", "Ù†ÙˆØ§Ù…Ø¨Ø±", "Ø¯Ø³Ø§Ù…Ø¨Ø±"
        ]

    def _clean_html(self, text):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ HTML Ø§Ø² Ù…ØªÙ†"""
        if not text:
            return ""
        # Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML
        text = re.sub(r'<[^>]+>', '', text)
        # ØªØ¨Ø¯ÛŒÙ„ entities Ø¨Ù‡ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø¹Ø§Ø¯ÛŒ
        return html.unescape(text)

    def _convert_numbers(self, text):
        """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
        persian_numbers = {
            '0': 'Û°', '1': 'Û±', '2': 'Û²', '3': 'Û³', '4': 'Û´',
            '5': 'Ûµ', '6': 'Û¶', '7': 'Û·', '8': 'Û¸', '9': 'Û¹'
        }
        return ''.join(persian_numbers.get(c, c) for c in str(text))

    def _get_today_date_string(self):
        """Ø³Ø§Ø®Øª Ø±Ø´ØªÙ‡ ØªØ§Ø±ÛŒØ® Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²"""
        tehran = timezone('Asia/Tehran')
        now = datetime.now(tehran)
        return (
            f"{self._convert_numbers(now.day)}_"
            f"{self.month_names[now.month - 1]}_"
            f"{self._convert_numbers(now.year)}"
        )

    async def fetch_daily_page(self):
        """Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø§Ù…Ø±ÙˆØ²"""
        date_str = self._get_today_date_string()
        page_title = f"Ù¾ÙˆØ±ØªØ§Ù„:Ø§Ø³Ø§ÛŒÛŒ Ø¯Ú©ØªÙ‡â€ŒØ¦ÙˆÙ†/Ø¯Ú©ØªÙ‡â€ŒØ¦ÙˆÙ†_{date_str}"

        params = {
            'action': 'query',
            'format': 'json',
            'prop': 'extracts|info',
            'exintro': True,
            'explaintext': True,
            'titles': page_title,
            'inprop': 'url',
            'utf8': True
        }

        try:
            logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {page_title}")
            response = requests.get(self.base_url, params=params, timeout=15)
            response.raise_for_status()
            data = response.json()

            pages = data.get('query', {}).get('pages', {})
            if not pages or '-1' in pages:
                return None

            page_id = next(iter(pages))
            page_info = pages[page_id]

            return {
                'title': page_info.get('title'),
                'extract': self._clean_html(page_info.get('extract', '')),
                'url': f"https://mzn.wikipedia.org/wiki/{quote(page_info.get('title', ''))}"
            }

        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {str(e)}")
            return None

class TelegramBot:
    def __init__(self):
        self.bot = Bot(token=TOKEN)

    async def send_message(self, content):
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
        try:
            content = content[:4000] + "..." if len(content) > 4000 else content

            await self.bot.send_message(
                chat_id=CHANNEL_ID,
                text=content,
                disable_web_page_preview=True,
                parse_mode='Markdown'
            )
            return True
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…: {str(e)}")
            return False

async def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§"""
    wikifetcher = WikipediaFetcher()
    telegram_bot = TelegramBot()

    page_data = await wikifetcher.fetch_daily_page()
    if not page_data:
        content = (
            f"*âš ï¸ Ø§Ù…Ø±ÙˆØ² ÙˆØ³Ù‡ Ù‡ÙÙ†ØªØ§ Ù‡ÛŒÚ† Ø®ÙÙˆØ±ÛŒ Ù†ÛŒâ€ŒÛŒØ´ØªÙ†Ù‡*\n\n"
            f"*Ø´Ù…Ø§ ØªÙˆÙ†Ø¯ÛŒ Ú©Ø³ÛŒ Ø¨ÙˆØ¦ÛŒ Ú©Ù‡ Ø£Ù…Ø±ÙˆØ² Ø§Ø®Ø¨Ø§Ø± Ø±Ù‡ Ù…Ø§Ø²Ø±ÙˆÙ†ÛŒ Ø²ÙˆÙˆÙ† Ø¬Ù‡ Ù†ÙˆÛŒØ³Ù†Ù‡*\n\n"
            f"[ğŸ”— Ø§ÛŒÙ†Ø¬Ù‡ Ø±Ù‡ Ø¨Ø²Ù† Ùˆ ÛŒØ§Ø¯ Ø¨ÙÛŒ Ú†ØªÛŒâ€ŒØ¦Ù‡]({page_data.get('https://w.wiki/ENC6', 'https://w.wiki/ENC6')})"
        )
    else:
        content = (
            f"*ğŸ“… {wikifetcher._get_today_date_string().replace('_', ' ')}*\n\n"
            f"*ğŸ“š {page_data.get('extract', 'Ø£Ù…Ø±ÙˆØ² Ø®ÙˆØ±')}*\n\n"
            f"ğŸ”— [Ù…Ù†Ø¨Ø¹]({page_data.get('url', 'https://mzn.wikipedia.org')})\n"
            f"*ğŸŒ @Mazeruni_Xaver*"
        )

    success = await telegram_bot.send_message(content)
    logger.info(f"Ù¾ØºÙˆÙ… Ø±Ø§Ù‡ÛŒ Ù‡Ø§Ú©Ø±Ø¯Ù† {'Ù…ÙˆÙÙ‚' if success else 'Ù†Ø§Ù…ÙˆÙÙ‚'} Ø¨ÛŒâ€ŒÛŒÙ‡")

if __name__ == "__main__":
    asyncio.run(main())
